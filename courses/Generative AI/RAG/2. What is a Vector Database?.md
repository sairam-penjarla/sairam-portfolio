# 2. What is a Vector Database?

## **What is a Vector?**

A **vector** is a multi-dimensional representation of data, often used to encode the meaning of objects like text, images, or audio. Think of it as a numerically expressed version of "context" or "meaning." For instance:

- A text like "I love pizza" could be represented as `[0.2, 0.7, 0.1, ...]`.
- An image of a cat could be represented as `[1.5, -0.3, 2.7, ...]`.

Vectors measure how close or far apart two entities are based on similarity. Similar entities will have vectors closer to each other in the high-dimensional space.

---

## **How Are Vectors Created?**

Vectors are typically created using **embeddings**, which are machine-learned transformations of raw data. Some popular models used to generate embeddings include:

1. **Text:** OpenAI’s embeddings, BERT, Sentence Transformers.
2. **Images:** CLIP, ResNet, Vision Transformers.
3. **Audio:** Wav2Vec, Audio embeddings from AI models.

Here’s an example of how a vector for text might be generated using Python:

```python
from transformers import AutoTokenizer, AutoModel
import torch
import torch.nn.functional as F

#Mean Pooling - Take attention mask into account for correct averaging
def mean_pooling(model_output, attention_mask):
    token_embeddings = model_output[0] #First element of model_output contains all token embeddings
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

# Sentences we want sentence embeddings for
sentences = ['This is an example sentence', 'Each sentence is converted']

# Load model from HuggingFace Hub
tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

# Tokenize sentences
encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')

# Compute token embeddings
with torch.no_grad():
    model_output = model(**encoded_input)

# Perform pooling
sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])

# Normalize embeddings
sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)

print("Sentence embeddings:")
print(sentence_embeddings)

```

---

## **What is a Vector Database?**

A **Vector Database** is a specialized database designed to store, index, and query vectors efficiently. Rather than traditional row-column storage, vector databases organize multi-dimensional arrays in such a way that similarity-based searches (like "nearest neighbor") become lightning-fast.

For example:

- In e-commerce: "Find products similar to this one based on user embeddings."
- In chatbots: "Retrieve the FAQ answer closest to the context of a user's query."

---

## **How is a Vector Database Created?**

To build a vector database, you need:

1. A collection of vectors (representing data like text, images, or audio).
2. An indexing mechanism (like **HNSW**, **FAISS**, or others) to enable fast similarity searches.
3. Tools for querying the database using vector similarity metrics (e.g., cosine similarity).

## FAISS

```python
import faiss
import numpy as np

# Step 1: Create random vectors
dimension = 128  # Size of vector embeddings
num_vectors = 100  # Number of vectors
vectors = np.random.rand(num_vectors, dimension).astype('float32')

# Step 2: Build FAISS index
index = faiss.IndexFlatL2(dimension)  # L2 distance (Euclidean)

# Step 3: Add vectors to index
index.add(vectors)

# Step 4: Query the index
query_vector = np.random.rand(1, dimension).astype('float32')
distances, indices = index.search(query_vector, k=5)  # Find top-5 closest vectors

print("Closest Distances:", distances)
print("Closest Vector Indices:", indices)

```

## Chroma DB

### 1. Install Chroma

```bash
pip install chromadb
```

---

### 2. Create a Persistent Client

```python
	import chromadb
	
	# Use persistent storage (will create ./chroma_data if not exists)
	client = chromadb.PersistentClient(path="./chroma_data")
	
```

---

### 3. Create or Get a Collection

```python
collection = client.get_or_create_collection(name="my_collection")

```

---

### 4. Insert Documents

```python
collection.add(
    documents=[
        # Topic 1: Space Exploration
        "The Hubble Space Telescope has been orbiting Earth since 1990.",
        "NASA’s Artemis program aims to return humans to the Moon.",
        "Mars rovers like Perseverance are searching for signs of past life.",

        # Topic 2: Ancient History
        "The pyramids of Giza were built during Egypt’s Old Kingdom.",
        "The Roman Empire reached its peak under Emperor Trajan.",
        "The Indus Valley Civilization thrived around 2500 BCE.",

        # Topic 3: Modern Technology
        "Quantum computing leverages qubits to perform complex calculations.",
        "5G networks offer faster speeds and lower latency than 4G.",
        "Artificial Intelligence is transforming industries worldwide.",

        # Topic 4: Food & Cooking
        "Italian pasta comes in many shapes like penne, fusilli, and spaghetti.",
        "Sushi originated in Japan as a method of preserving fish.",
        "Sourdough bread is made using natural fermentation.",

        # Topic 5: Sports
        "The Olympics are held every four years with summer and winter editions.",
        "Football is the most popular sport globally, followed by cricket.",
        "Tennis Grand Slam tournaments include Wimbledon and the US Open."
    ],
    ids=[
        # Topic 1 IDs
        "doc1", "doc2", "doc3",
        # Topic 2 IDs
        "doc7", "doc8", "doc9",
        # Topic 3 IDs
        "doc10", "doc11", "doc12",
        # Topic 4 IDs
        "doc13", "doc14", "doc15",
        # Topic 5 IDs
        "doc16", "doc17", "doc18"
    ],
    metadatas=[
        # Topic 1 Metadata
        {"source": "space"}, {"source": "space"}, {"source": "space"},
        # Topic 2 Metadata
        {"source": "history"}, {"source": "history"}, {"source": "history"},
        # Topic 3 Metadata
        {"source": "technology"}, {"source": "technology"}, {"source": "technology"},
        # Topic 4 Metadata
        {"source": "food"}, {"source": "food"}, {"source": "food"},
        # Topic 5 Metadata
        {"source": "sports"}, {"source": "sports"}, {"source": "sports"}
    ]
)

```

---

### 5. Query the Collection

```python
results = collection.query(
    query_texts=["What is sushi?"],
    n_results=2
)

print(results)

```

---

### 6. Update a Document

```python
collection.update(
    ids=["doc2"],
    documents=["ChromaDB is often used for building AI/LLM apps with embeddings."]
)

```

---

### 7. Delete a Document

```python
collection.delete(ids=["doc3"])

```

---

### 8. List Collections

```python
print(client.list_collections())

```

---

### **Different Vector Databases in the Market**

1. **Pinecone:**
    - Managed vector database with built-in scaling and search optimization.
    - Offers support for real-time updates and metadata filtering.
2. **Weaviate:**
    - Open-source with a lightweight server and powerful extensions for semantic search.
    - Allows combining unstructured data (vectors) with structured metadata (schema).
3. **Milvus:**
    - Open-source vector database designed for massive-scale similarity searches.
    - Integrates well with a variety of machine learning pipelines.
4. **FAISS:**
    - Library created by Facebook AI for nearest-neighbor search.
    - Focused on efficiency but lacks the database-like management aspects.
5. **Chroma:**
    - A lightweight vector database built specifically for developers.
    - Seamlessly integrates with Python, handling embeddings and matching easily.

---

## **How Do They Differ?**

| **Database** | **Key Features** | **Advantages** | **Drawbacks** |
| --- | --- | --- | --- |
| **Pinecone** | Scalable, managed service with filtering | No ops management, fast | Not open-source, costs may escalate |
| **Weaviate** | Schema-driven + open-source | Easy setup, semantic power | Requires infrastructure setup |
| **Milvus** | Handles billions of vectors | Designed for scalability | Heavy resources, non-trivial scaling |
| **FAISS** | High-efficiency search | Lightweight, customizable | Lacks database functionalities |
| **Chroma** | Developer-focused simplicity | Pythonic, fast prototyping | Limited production features |

---

## **Advantages of Vector Databases**

1. **Speedy Searches:**
    - Vector databases use indexing techniques like **HNSW** (Hierarchical Navigable Small World Graphs), making similarity searches ultra-fast.
2. **Scalability:**
    - Can handle billions of vectors, making them ideal for enterprise-scale applications.
3. **Versatility:**
    - Use cases span semantic search, recommendation engines, NLP assistants, and much more.
4. **Metadata Integration:**
    - Many vector databases integrate metadata filtering (e.g., filter by category or tag).

---

## **Disadvantages of Vector Databases**

1. **Resource Intensity:**
    - Building and querying large-scale vector databases can require significant computing power.
2. **Complexity:**
    - Finding the right database, indexing method, and retrieval setup requires expertise.
3. **Cost:**
    - Managed services (like Pinecone) can be quite expensive for large-scale operations.
4. **Limitations with Non-Vector Data:**
    - Purely vector-focused systems may not handle traditional structured data well, leading to the need for hybrid systems.

---

## **Conclusion**

Vector databases are a game-changer in AI and data science, helping bridge the gap between raw data and meaningful insights. Whether it's Pinecone for ease, Milvus for scalability, or FAISS for efficiency, each comes with its own set of strengths.