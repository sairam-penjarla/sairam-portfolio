# Building Your First AI Agent: From Setup to Execution

In the previous blog, we explored the conceptual foundations of AI agentsâ€”what makes them different from chat completion systems and RAG, and why they represent the next evolution in AI systems. Now it's time to roll up our sleeves and build one.

In this blog, we'll create a functional AI agent from scratch, understand the core components that make it work, and explore how to interact with it programmatically. By the end, you'll have a working agent and understand the architecture that powers it.

## Setting Up the Foundation

Before we can build an agent, we need to establish our connection to the underlying language model. We'll use Azure OpenAI in this example, but the principles apply to any LLM provider.

```python
import os
from dotenv import load_dotenv
from openai import AsyncAzureOpenAI
from agents import Agent, OpenAIChatCompletionsModel, function_tool, Runner

load_dotenv()

agent_client = AsyncAzureOpenAI(
    api_key=os.getenv("GPT_4_1_AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("GPT_4_1_AZURE_OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("GPT_4_1_AZURE_OPENAI_API_ENDPOINT"),
    azure_deployment=os.getenv("GPT_4_1_AZURE_OPENAI_API_MODEL_NAME"),
)
model_name = os.getenv("GPT_4_1_AZURE_OPENAI_API_MODEL_NAME")

```

### What's Happening Here?

1. **Environment Variables**: We're using `dotenv` to load sensitive credentials from a `.env` file. This is a best practiceâ€”never hardcode API keys in your source code.
2. **AsyncAzureOpenAI Client**: We're creating an asynchronous client for Azure OpenAI. The `async` nature is crucial for agents because they often need to make multiple API calls, wait for tool executions, and handle concurrent operations efficiently.
3. **Configuration Parameters**:
    - `api_key`: Your authentication credential
    - `api_version`: The API version you're targeting
    - `azure_endpoint`: The specific Azure endpoint for your deployment
    - `azure_deployment`: The name of your deployed model

This setup creates the communication channel between your agent framework and the language model that powers its intelligence.

## Creating Your First Agent

Now comes the exciting partâ€”defining the agent itself:

```python
custom_agent = Agent(
    name="My Custom Agent",
    instructions="You are a conversational AI assistant. Answer the user's questions based on your knowledge",
    model=OpenAIChatCompletionsModel(model=model_name, openai_client=agent_client),
)

```

### Anatomy of an Agent

Let's break down each component:

**1. Name**: `"My Custom Agent"`

The name isn't just for identificationâ€”it becomes part of the agent's identity. In multi-agent systems (which we'll cover later), agents can reference each other by name, and the name helps in logging, debugging, and orchestration.

**2. Instructions**: The Agent's Constitution

```python
instructions="You are a conversational AI assistant. Answer the user's questions based on your knowledge"

```

Instructions are the foundational prompt that shapes your agent's behavior. Think of them as the agent's constitutionâ€”the core principles it operates under. These instructions:

- Define the agent's role and personality
- Set boundaries on what the agent should and shouldn't do
- Establish the tone and style of responses
- Can include specific guidelines, constraints, or domain expertise

Unlike a simple chat completion system where you might repeat context in every message, agent instructions persist across all interactions. They're always present, shaping every decision the agent makes.

**3. Model**: The Brain

```python
model=OpenAIChatCompletionsModel(model=model_name, openai_client=agent_client)

```

This wraps our Azure OpenAI client in an agent-compatible interface. The `OpenAIChatCompletionsModel` adapter translates between the agent framework's expectations and OpenAI's API format. This abstraction means you could swap in different model providers (Anthropic, Google, local models) without rewriting your agent logic.

## Running the Agent

With our agent defined, let's see it in action:

```python
result = await Runner.run(
    custom_agent,
    input="hey hi",
)
print(result.final_output)

```

**Output:**

```
Hi there! How can I help you today?

```

### Understanding the Runner

The `Runner` is the execution engine that brings agents to life. Here's what happens when you call `Runner.run()`:

1. **Initialization**: The Runner prepares the agent's context with the instructions
2. **Input Processing**: Your message is formatted and sent to the agent
3. **Execution Loop**: The agent processes the input, potentially making multiple internal decisions
4. **Response Generation**: The agent formulates its response
5. **Result Packaging**: Everything is wrapped up in a structured result object

The `await` keyword indicates this is an asynchronous operation. The agent might be doing multiple thingsâ€”reasoning about the query, deciding whether to use tools, generating a responseâ€”and async/await lets your program remain responsive during these operations.

### What's in the Result?

The `result` object contains more than just the final output. It's a comprehensive record of what the agent did:

- **final_output**: The agent's response text
- **conversation_history**: A full trace of the interaction
- **tool_calls**: Any tools the agent used (if applicable)
- **metadata**: Timing, token usage, and other execution details

This rich result object is crucial for debugging, auditing, and understanding agent behavior.

## Rendering Results in Jupyter

If you're working in a Jupyter notebook, you can make the output more visually appealing:

```python
from IPython.display import display, Markdown

display(Markdown("# ðŸ§  Hello\nThis is **Markdown** rendered inside Jupyter!"))

```

**Output:**

```
ðŸ§  Hello
This is Markdown rendered inside Jupyter!

```

```python
display(Markdown(result.final_output))

```

**Output:**

```
Hi there! How can I help you today?

```

This is particularly useful when your agent generates formatted content, code blocks, or structured information. Instead of seeing raw markdown syntax, you get beautifully rendered output right in your notebook.

## Inspecting the Conversation Structure

One of the most powerful features of agents is their structured conversation handling. Let's peek under the hood:

```python
result.to_input_list()

```

**Output:**

```python
[
  {
    'content': 'hey hi',
    'role': 'user'
  },
  {
    'id': '__fake_id__',
    'content': [
      {
        'annotations': [],
        'text': 'Hi there! How can I help you today?',
        'type': 'output_text'
      }
    ],
    'role': 'assistant',
    'status': 'completed',
    'type': 'message'
  }
]

```

### Deconstructing the Conversation Format

This structured format reveals how agents organize conversations:

**User Message:**

```python
{
    'content': 'hey hi',
    'role': 'user'
}

```

Simple and directâ€”the user's input with their role clearly marked.

**Assistant Message:**

```python
{
    'id': '__fake_id__',
    'content': [...],
    'role': 'assistant',
    'status': 'completed',
    'type': 'message'
}

```

Much richer! Let's examine each field:

- **id**: A unique identifier for this message. The `__fake_id__` is a placeholder, but in production systems, these IDs are used for tracking, referencing, and updating messages.
- **content**: An array of content blocks. This allows for multi-modal responses (text, images, tool results) all in one message. Each block has:
    - `text`: The actual response content
    - `type`: What kind of content this is (`output_text`, `tool_call`, etc.)
    - `annotations`: Metadata like citations, confidence scores, or references
- **role**: `assistant` indicates this came from the agent
- **status**: `completed` means the agent finished generating this response. Other statuses might be `in_progress`, `requires_action`, or `failed`.
- **type**: `message` distinguishes this from other conversation elements like function calls or system notifications

### Why This Structure Matters

This standardized format is what enables powerful agent capabilities:

1. **Memory Management**: The structured format makes it easy to store and retrieve conversation history
2. **Context Building**: When resuming a conversation, you can reconstruct the exact state
3. **Tool Integration**: Tool calls and results fit naturally into this structure
4. **Multi-Agent Communication**: Agents can pass these structured messages to each other
5. **Debugging and Logging**: You can trace exactly what happened at each step

## The Agent Lifecycle in Action

Let's trace through what just happened when we ran our simple "hey hi" query:

1. **Initialization Phase**
    - Runner loads the agent's instructions
    - Model client is prepared and ready
    - Conversation context is initialized
2. **Input Phase**
    - User message "hey hi" is formatted as a structured message
    - Message is added to conversation history
    - Context window is prepared with instructions + history
3. **Processing Phase**
    - Agent receives the combined context
    - Model analyzes the input (a simple greeting)
    - Determines no tools are needed
    - Generates an appropriate conversational response
4. **Output Phase**
    - Response is structured into the standard format
    - Status is marked as completed
    - Result object is created with full conversation history
5. **Return Phase**
    - Runner returns the comprehensive result
    - We extract `final_output` for display
    - Full conversation structure remains available for inspection

## What We've Accomplished

In just a few lines of code, we've created a functioning AI agent with:

- âœ… A persistent identity (name and instructions)
- âœ… Connection to a powerful language model
- âœ… Structured conversation handling
- âœ… Asynchronous execution for efficiency
- âœ… Comprehensive result tracking
- âœ… Conversation history management

## Key Differences from Simple Chat Completion

Compare what we just built to a basic chat completion call:

**Simple Chat Completion:**

```python
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "hey hi"}]
)
print(response.choices[0].message.content)

```

**Our Agent:**

```python
result = await Runner.run(custom_agent, input="hey hi")
print(result.final_output)

```

They look similar, but the agent version includes:

- Persistent instructions across all calls
- Structured conversation management
- Extensibility for tools and memory (coming next)
- Rich metadata and execution tracking
- Foundation for multi-turn interactions

## What's Next

Our agent right now is conversational but not very powerfulâ€”it can only talk, not act. In the next blog, we'll add **memory** to our agent, giving it the ability to remember context across multiple interactions, learn user preferences, and maintain state.

After that, we'll introduce **tools**â€”the hands and eyes that let our agent interact with the real world. That's when things get really interesting.

## Try It Yourself

Before moving on, experiment with your agent:

1. **Change the instructions**: Make it a Python expert, a creative writer, or a data analyst. See how the personality changes.
2. **Try different inputs**: Ask questions, give commands, have a multi-turn conversation (we'll see how to do this properly next time).
3. **Inspect the results**: Use `to_input_list()` to see the full conversation structure. Notice how it evolves.
4. **Break it**: What happens with very long inputs? Empty strings? Non-English text?

Understanding these basics deeply will make everything else in this series click into place. The agent we built today is simple, but it contains all the core concepts we'll build upon.

---

*In the next blog, we'll implement memory systems that let our agent remember conversations, maintain context, and build genuine understanding over time.*